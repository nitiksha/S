SPARK CLOUD INTEGRATION


package pack

import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.types._
import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions._

object obj {




	def main(args:Array[String]):Unit={

			println("===Hello====")

			val conf = new SparkConf().setAppName("first").setMaster("local[*]").set("spark.driver.host","localhost")
			.set("spark.driver.allowMultipleContexts", "true")

			val sc = new SparkContext(conf)

			sc.setLogLevel("ERROR")

			val spark = SparkSession.builder.getOrCreate()

			import spark.implicits._
			
		
			
			val  df = spark
			          .read
			          .format("json")
			          .option("fs.s3a.access.key","")
			          .option("fs.s3a.secret.key","")
			          .load("s3a://zeyotics/cashdata")
			
			
			
			df.show()
			

	}

}
